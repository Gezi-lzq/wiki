created: 20241116162300973
creator: Gezi-lzq
modified: 20241117103501161
modifier: Gezi-lzq
tags: iceberg
title: 在 Apache Iceberg 中写 queries

Apache Iceberg 中的 write process 涉及一系列步骤，使 query engines 能够高效地插入和更新数据。当一个 write query 被启动时，它会被发送到 engine 进行解析。

然后 consult catalog 以确保数据的一致性和完整性，并根据定义的 partition strategies 写入数据。

数据文件和 metadata 文件会根据 query 写入。最后，catalog file 会被更新以反映最新的 metadata，从而支持后续的 read operations 去 access 最新版本的数据。

[img[Iceberg_write_process.png]]

! Create the Table

下面将从创建一个 Iceberg Table 开始，理解其中的底层过程。在下面这个 example query 中，将会创建一个名为 orders 的table， 包含 4 个 columns。
（在下面将展示 Spark 与 Dremio 的 SQL Query Engine 中执行操作需要的SQL）

```SQL
# Spark SQL
CREATE TABLE orders (
	order_id BIGINT,
	customer_id BIGINT,
	order_amount DECIMAL(10, 2),
	order_ts TIMESTAMP
)
USING iceberg
PARTITIONED BY (HOUR(order_ts))

# Dremio
CREATE TABLE orders (
	order_id BIGINT,
	customer_id BIGINT,
	order_amount DECIMAL(10, 2),
	order_ts TIMESTAMP
)
PARTITION BY (HOUR(order_ts))
```

! 把 query 发送到 engine

首先，query 被发送到 query engine 进行解析。然后，因为这是一个 CREATE statement，engine 会开始创建和定义表。

! 写 metadata 文件

在这个阶段，engine 开始在 data lake 文件系统中创建一个名为 v1.metadata.json 的 metadata 文件，用于存储关于 table 的信息。路径的通用 URL 形式看起来像这样：`s3://path/to/warehouse/db1/table1/metadata/v1.metadata.json`。

根据 `/path/to/warehouse/db1/table1` 的信息，engine 写入 metadata 文件。然后通过指定 columns 和 data types 来定义 orders 表 的 schema，并将其存储在 metadata 文件中。最后，它为 table 分配一个唯一的标识符：table-uuid。一旦 query 成功执行，metadata 文件 v1.metadata.json 就会写入 data lake file storage。

```
s3://datalake/db1/orders/metadata/v1.metadata.json
```

如果你检查 metadata 文件，你会看到定义表的 schema 以及 partition specification:

```json
{
  "table-uuid": "072db680-d810-49ac-935c-56e901cad686",
  "schema": {
    "type": "struct",
    "schema-id": 0,
    "fields": [
      {
        "id": 1,
        "name": "order_id",
        "required": false,
        "type": "long"
      },
      {
        "id": 2,
        "name": "customer_id",
        "required": false,
        "type": "long"
      },
      {
        "id": 3,
        "name": "order_amount",
        "required": false,
        "type": "decimal(10, 2)"
      },
      {
        "id": 4,
        "name": "order_ts",
        "required": false,
        "type": "timestamptz"
      }
    ]
  },
  "partition-spec": [
    {
      "name": "order_ts_hour",
      "transform": "hour",
      "source-id": 4,
      "field-id": 1000
    }
  ]
}
```

这是当前的 table 状态；你已经创建了一个 table，但它是一个没有 records 的 empty table。在 Iceberg 术语中，这被称为 snapshot 。

这里需要注意的是，由于你还没有插入任何 records，所以 table 中没有 actual data，因此你的 data lake 中没有 datafiles。因此，snapshot 不会指向任何 manifest list；因此，没有 manifest files。

! 更新 catalog 文件以 commit 更改

最后，engine 更新当前的 metadata 指针，指向 catalog 文件中的 v1.metadata.json 文件，因为这是 table 的当前状态。需要注意的是，catalog 文件的名字 version-hint.text 是特定于 catalog 选择的。在这个示例中，我们使用了基于 filesystem 的 Hadoop catalog。下图展示了 table 创建后 Iceberg 组件的 hierarchy。

[img[hierarchy_of_iceberg_components.png]]

! 插入 the query

现在让我们插入一些 records 到 table 中并了解其工作原理。我们已经创建了一个名为 orders 的 table，包含四个 columns。在这个示范中，我们将输入以下 values 到 table 中：order_id 为 123，customer_id 为 456，order_amount 为 36.17，order_ts 为 2023-03-07 08:10:23。

```SQL
# Spark SQL/Dremio's SQL Query Engine
INSERT INTO orders VALUES (
	123,
	456,
	36.17,
	'2023-03-07 08:10:23'
)
```

! 把 query 发送到 engine

The query 被发送到 query engine 进行 parsing。因为这是一个 `INSERT statement`，engine 需要关于 table 的信息，比如它的 schema，以开始 query planning。

! 检查 catalog

首先，query engine 会向 catalog 请求以确定当前 metadata 文件的位置，然后读取它。因为我们使用的是 Hadoop catalog，engine 会读取 `/orders/metadata/version-hint.txt` 文件，并看到文件内容是一个单一的整数：1。

基于此，并利用 catalog 实现中的逻辑，engine 知道当前 metadata 文件的位置是 `/orders/metadata/v1.metadata.json`，这是我们之前 `CREATE TABLE` 操作创建的文件。所以 engine 会读取这个文件。尽管在这种情况下 engine 的目的是插入新的 datafiles，它仍然会与 catalog 交互，主要有两个原因：

* The engine 需要理解当前表的 schema 以遵循它。
* The engine 需要在写入时了解 partitioning scheme 来组织数据。

! 写 datafiles 和 metadata files

在 engine 了解 table schema 和 partitioning scheme 之后，它开始写入新的 datafiles 和相关的 metadata files。以下是这个过程中的具体步骤。

首先，engine 将记录写成 Parquet 数据文件（Parquet 是默认的，但可以更改），基于表的每小时定义的 partitioning scheme。

此外，如果为表定义了 sort order，记录将在写入 datafile 之前进行排序。这就是它在 filesystem 中的样子：

```
s3://datalake/db1/orders/data/order_ts_hour=2023-03-07-08/0_0_0.parquet
```

在写入 datafile 之后，engine 会创建一个 manifest file。这个 manifest file 包含了关于 engine 创建的实际 datafile 路径的信息。此外，engine 还会在 manifest file 中写入统计信息，例如列的 upper 和 lower bounds 以及 null value counts，这对 query engine 修剪文件和提供最佳性能非常有利。

engine 在处理即将写入的数据时计算这些信息，因此这是一个相对轻量的操作，至少相比从头开始计算统计信息的过程。manifest file 会作为.avro 文件写入存储系统中。

```
s3://datalake/db1/orders/metadata/62acb3d7-e992-4cbc-8e41-58809fcacb3e.avro
```

这是一个 manifest 文件内容的 JSON 表示(仅展示了需要关注的部分信息)。

```json
{
  "data_file": {
    "file_path": "s3://datalake/db1/orders/data/order_ts_hour=2023-03-07-08/0_0_0.parquet",
    "file_format": "PARQUET",
    "block_size_in_bytes": 67108864,
    "null_value_counts": [],
    "lower_bounds": {
      "array": [
        {
          "key": 1,
          "value": 123
        }
      ]
    },
    "upper_bounds": {
      "array": [
        {
          "key": 1,
          "value": 123
        }
      ]
    }
  }
}
```

接下来，engine 创建一个 manifest list 来跟踪 manifest file。如果现有的 manifest files 与这个 snapshot 相关联，它们也会被添加到这个新的 manifest list 中。

engine 将这个文件写入 data lake，包含的信息如 manifest file 的路径、添加或删除的 datafiles/rows 数量以及关于 partitions 的统计信息，例如 partition columns 的上下界。同样，engine 已经拥有所有这些信息，所以有这些 statistics 是一个轻量级的操作。这些信息帮助读取 queries 排除任何不需要的 manifest 文件，从而加快 queries 速度。

```
s3://datalake/db1/orders/metadata/snap-8333017788700497002-1-4010cc03-5585-458c-9fdc-188de318c3e6.avro
```

这里是 manifest list 内容的一个片段：

```json
{
  "manifest_path": "s3://datalake/db1/orders/metadata/62acb3d7-e992-4cbc-8e41-58809fcacb3e.avro",
  "manifest_length": 6152,
  "added_snapshot_id": 8333017788700497002,
  "added_data_files_count": 1,
  "added_rows_count": 1,
  "deleted_rows_count": 0,
  "partitions": {
    "array": [
      {
        "contains_null": false,
        "lower_bound": {
          "bytes": "¹Ô\u0006\u0000"
        },
        "upper_bound": {
          "bytes": "¹Ô\u0006\u0000"
        }
      }
    ]
  }
}
```

最后，engine 创建了一个新的 metadata 文件 `v2.metadata.json` ，并生成了一个新的 `snapshot-s1`。在这个过程中，engine 参考了现有的、之前被认为是当前元数据文件的 `v1.metadata.json`, 同时记录了上一个 `snapshot-s0`。这个新的元数据文件包括 engine 创建的 manifest list 信息，其中包括例如manifest list 文件路径、snapshot id 以及 operation summary 等详细信息。

此外，engine 还指明了最近生成的 manifest 列表或快照是当前应使用的版本。

```
s3://datalake/db1/orders/metadata/v2.metadata.json
```

以下是这个新的 metadata 文件的部分内容示例：

```json
{
  "current-snapshot-id": 8333017788700497002,
  "refs": {
    "main": {
      "snapshot-id": 8333017788700497002,
      "type": "branch"
    }
  },
  "snapshots": [
    {
      "snapshot-id": 8333017788700497002,
      "summary": {
        "operation": "append",
        "added-data-files": "1",
        "added-records": "1"
      },
      "manifest-list": "s3://datalake/db1/orders/metadata/snap-8333017788700497002-1-4010cc03-5585-458c-9fdc-188de318c3e6.avro"
    }
  ]
}
```

! 更新 catalog 文件以 commit 更改

现在 engine 再次访问 catalog，确保在执行这个 INSERT 操作时没有其他 snapshots 被提交。通过这种 validation，Iceberg 保证了在多个 writers 同时写数据的情况下操作不会互相干扰。

在任何 write 操作中，Iceberg 乐观地创建 metadata files，假设当前版本在 writer 提交之前不会改变。完成 write 后，engine 通过将 table 的 metadata file pointer 从现有的 base version 切换到新的版本 v2.metadata.json 来原子性地 commit，这样新版本就成为了当前的 metadata file。

[img[iceberg_component's_hierarchy_after_executing_INSERT.png]]