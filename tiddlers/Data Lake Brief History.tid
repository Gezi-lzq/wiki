created: 20241102150300168
creator: Gezi-lzq
modified: 20241109163931651
modifier: Gezi-lzq
tags: DataLake feed
title: Data Lake Brief History

在最初，你会采用 Hadoop ，一个开源的分布式计算框架，以及其HDFS文件系统组件，在由廉价计算机组成的集群中 存储和处理大量结构化和非结构化的数据集。 但仅仅存储这些数据还不够，你还希望对其进行分析。

Hadoop 生态系统包含了 MapReduce，这是一个分析框架，用户可以用 Java 编写分析作业并在 Hadoop 集群上运行。编写 MapReduce 作业时代码冗长且复杂，而许多分析师更习惯于编写 SQL 而不是 Java，因此 Hive 被创建出来，用来将 SQL 语句转换成 MapReduce 作业。

为了编写SQL，还需要一个机制用来区分存储中哪些文件属于特定的数据集或表，这就诞生了 Hive 表格式，该格式将一个目录乃其内部的文件识别为一个表。

随着时间的推移，人们逐渐放弃了使用 Hadoop 集群，转而使用云对象存储（例如 AWS S3、 Minio、 Azure Blob Storage），因为它们更容易管理且成本更低。

MapReduce 也逐渐被其他分布式查询引擎（如 Apache Spark、 Presto 和 Dremio）所取代。然而，Hive 表格式却保留了下来，它成为了识别存储中文件为单一表的标准，可以在其上运行分析。然而，云存储在访问这些文件时需要更多的网络成本，这是 Hive 格式架构所没有预料的，也导致了由于 Hive 对表文件夹结构的依赖而产生了更多的网络调用。

数据湖和数据仓库的区别在于能够针对不同的工作负载使用不同的计算引擎。这一点很重要，因为从来没有一种万能的计算引擎能够适用于所有工作负载，并且能够独立于存储进行扩展。这仅仅是计算的本质，因为总是存在权衡，而你做出的权衡决定了特定系统擅长什么，不擅长什么。

请注意，在数据湖中，实际上并没有任何服务能够满足存储引擎的功能需求。通常情况下，在数据湖环境中，数据的写入和管理主要由计算引擎决定，而一旦数据写入后通常不会进行进一步的优化，只有在特定需求下才会临时决定整个表或分区的重写操作。

[img[Technical_components_of_a_data_lake.png]]
